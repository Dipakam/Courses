{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cs771 import genSyntheticData as gsd\n",
    "from cs771 import plotData as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import time as tm\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas\n",
    "\n",
    "Z = np.loadtxt( \"data\" )\n",
    "\n",
    "y = Z[:,0]\n",
    "X = Z[:,1:]\n",
    "\n",
    "\n",
    "# Quite standard for strongly convex but non-smooth objectives like CSVM\n",
    "def getStepLength( grad, t ,power):\n",
    "    return eta/pow(t,power)\n",
    "\n",
    "#function that returns the sum of hingelosses for all the points __ useful for calculation of gradient \n",
    "def hingeloss(theta):\n",
    "    w = theta[0:-1]\n",
    "    b = theta[-1]\n",
    "    hinge = np.maximum(1-np.multiply((X.dot(w) + b), y), 0)\n",
    "    return np.sum(hinge)\n",
    "\n",
    "# # Get the gradient of the objective function at a given w and b\n",
    "# def gradient( theta ):\n",
    "#     w = theta[0:-1]\n",
    "#     b = theta[-1]\n",
    "#     hingeLoss = np.maximum( 1 - np.multiply( (X.dot( w ) + b), y ), 0 )\n",
    "#     XiYi = np.multiply(X,y[:,np.newaxis])\n",
    "#     hingelossXiyi = np.multiply(XiYi,hingeLoss[:,np.newaxis])\n",
    "#     return  w - 2*C * np.sum( hingeLoss,axis = 0 )\n",
    "  \n",
    "    \n",
    "# Get the CSVM gradient\n",
    "def CSVMgradient( theta ):\n",
    "    w = theta[0:-1]\n",
    "    b = theta[-1]\n",
    "    discriminant = 1 - np.multiply( (X.dot( w ) + b), y )\n",
    "#     g = np.zeros( (y.size,) )\n",
    "#     g[discriminant < 1] = -1\n",
    "    delb = C * np.maximum(discriminant,0).dot( y ) * (-2)\n",
    "    delw = w + C * (X.T * np.maximum(discriminant,0)).dot( y ) * (-2)\n",
    "    return np.append( delw, delb )\n",
    "\n",
    "    \n",
    "# Get the CSVM objective value in order to plot convergence curves\n",
    "def getCSVMObjVal( theta ):\n",
    "    w = theta[0:-1]\n",
    "    b = theta[-1]\n",
    "    Loss = np.square(np.maximum( 1 - np.multiply( (X.dot( w ) + b), y ), 0 ))\n",
    "    return 0.5 * w.dot( w ) + C * np.sum( Loss )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.187531,  0.      ,  0.019502, ...,  0.023928,  0.      ,\n",
       "         0.016832],\n",
       "       [ 0.668091,  0.      , -0.027339, ...,  0.071717,  1.      ,\n",
       "        -0.081661],\n",
       "       [ 0.525146,  0.      , -0.093567, ..., -0.376834,  0.      ,\n",
       "        -0.050117],\n",
       "       ...,\n",
       "       [ 0.385101,  0.      ,  0.134089, ..., -0.147898,  0.      ,\n",
       "         0.050913],\n",
       "       [ 0.163391,  0.      , -0.01197 , ...,  0.123978,  0.      ,\n",
       "        -0.056383],\n",
       "       [ 0.244385,  0.      , -0.127514, ...,  0.01782 ,  0.      ,\n",
       "         0.3061  ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a stochastic gradient for the CSVM objective\n",
    "# Choose a random data point per iteration\n",
    "def getCSVMSGrad( theta ):\n",
    "    w = theta[0:-1]\n",
    "    b = theta[-1]\n",
    "    n = y.size\n",
    "    i = random.randint( 0, n-1 )\n",
    "    x = X[i,:]\n",
    "    discriminant = 1 - ((x.dot( w ) + b) * y[i])\n",
    "#     g = 0\n",
    "#     if discriminant < 1:\n",
    "#         g = -1\n",
    "    delb = C * y[i] * (-2) * np.maximum(descriminant,0)\n",
    "    delw = w + C * n * (x * np.maximum(descriminant,0)) * y[i] * (-2)\n",
    "    return np.append( delw, delb )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([136,  46,   5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a mini-batch stochastic gradient for CSVM\n",
    "# Choose a random set of B samples per iteration\n",
    "def getCSVMMBGrad( theta ):\n",
    "    w = theta[0:-1]\n",
    "    b = theta[-1]\n",
    "    n = y.size\n",
    "    if B <= n:\n",
    "        samples = random.sample( range(0, n), B )\n",
    "        X_ = X[samples,:]\n",
    "        y_ = y[samples]\n",
    "    else:\n",
    "        X_ = X\n",
    "        y_ = y\n",
    "    discriminant = 1 - np.multiply( (X_.dot( w ) + b), y_ )\n",
    "#     g = np.zeros( (B,) )\n",
    "#     g[discriminant < 1] = -1\n",
    "    delb = C * np.maximum(descriminant,0).dot( y_ ) * (-2)\n",
    "    delw = w + C * n/B * (X_.T * np.maximum(descriminant,0)).dot( y_ )* (-2)\n",
    "    return np.append( delw, delb )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 0, 2, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
